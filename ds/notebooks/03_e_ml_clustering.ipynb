{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaturDoc - TL BL WT 22-23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clustering:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including Required Code:\n",
    "\n",
    "### Loading Embeddings Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_embeddings = pd.read_csv(\"../data/embeddings/word_embeddings_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_symptom = symptoms_embeddings[\"Symptom\"].to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_1 = symptoms_embeddings.loc[0, \"Embedding1\"].replace(\"\\n\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")\n",
    "test_list_2 = symptoms_embeddings.loc[0, \"Embedding2\"].replace(\"\\n\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all empty strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-9.81967244e-03',\n",
       " '1.01662287e-02',\n",
       " '3.75229940e-02',\n",
       " '1.75703913e-02',\n",
       " '-1.11436069e-01']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_1 = [x for x in test_list_1 if x]\n",
    "test_list_2 = [x for x in test_list_2 if x]\n",
    "test_list_1[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating useable dataframes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding 1 column:\n",
    "\n",
    "First, transform content of rows from strings to lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '5.98840415e-02',\n",
       " '',\n",
       " '1.64022837e-02',\n",
       " '-4.90665212e-02',\n",
       " '',\n",
       " '4.81191762e-02\\n',\n",
       " '-9.69780684e-02',\n",
       " '-1.16978601e-01',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptoms_embeddings.loc[:, \"Embedding1\"].str.replace(\"[\", \"\", regex=True).replace(\"]\", \"\", regex=True).str.split(\" \")[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_df_values(df_series: pd.Series):\n",
    "    df_series = df_series.str.replace(\"\\n\", \"\", regex=True)\n",
    "    df_series = df_series.str.replace(\"[\", \"\", regex=True).replace(\"]\", \"\", regex=True)\n",
    "    df_series = df_series.str.split(\" \")\n",
    "    return df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1_series = listify_df_values(symptoms_embeddings.loc[:, \"Embedding1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1_series = embeddings1_series.apply(lambda row: [val for val in row if val])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/67442107/pandas-expand-explode-dataframe-horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-9.81967244e-03, 1.01662287e-02, 3.75229940e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.98840415e-02, 1.64022837e-02, -4.90665212e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6.30832557e-03, 6.94514960e-02, 9.17118881e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1.41132241e-02, 7.76526034e-02, -8.35783686e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-7.86128864e-02, -2.58876905e-02, 3.46109122e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Embedding1\n",
       "0  [-9.81967244e-03, 1.01662287e-02, 3.75229940e-...\n",
       "1  [5.98840415e-02, 1.64022837e-02, -4.90665212e-...\n",
       "2  [6.30832557e-03, 6.94514960e-02, 9.17118881e-0...\n",
       "3  [-1.41132241e-02, 7.76526034e-02, -8.35783686e...\n",
       "4  [-7.86128864e-02, -2.58876905e-02, 3.46109122e..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1_df = pd.DataFrame(embeddings1_series)\n",
    "embeddings1_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding1_0</th>\n",
       "      <th>Embedding1_1</th>\n",
       "      <th>Embedding1_2</th>\n",
       "      <th>Embedding1_3</th>\n",
       "      <th>Embedding1_4</th>\n",
       "      <th>Embedding1_5</th>\n",
       "      <th>Embedding1_6</th>\n",
       "      <th>Embedding1_7</th>\n",
       "      <th>Embedding1_8</th>\n",
       "      <th>Embedding1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Embedding1_374</th>\n",
       "      <th>Embedding1_375</th>\n",
       "      <th>Embedding1_376</th>\n",
       "      <th>Embedding1_377</th>\n",
       "      <th>Embedding1_378</th>\n",
       "      <th>Embedding1_379</th>\n",
       "      <th>Embedding1_380</th>\n",
       "      <th>Embedding1_381</th>\n",
       "      <th>Embedding1_382</th>\n",
       "      <th>Embedding1_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.81967244e-03</td>\n",
       "      <td>1.01662287e-02</td>\n",
       "      <td>3.75229940e-02</td>\n",
       "      <td>1.75703913e-02</td>\n",
       "      <td>-1.11436069e-01</td>\n",
       "      <td>3.83325890e-02</td>\n",
       "      <td>1.48906738e-01</td>\n",
       "      <td>4.44466770e-02</td>\n",
       "      <td>5.77533916e-02</td>\n",
       "      <td>-1.21526700e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.11344092e-02</td>\n",
       "      <td>1.98782869e-02</td>\n",
       "      <td>1.33477971e-02</td>\n",
       "      <td>3.86779606e-02</td>\n",
       "      <td>-4.79677059e-02</td>\n",
       "      <td>3.42200510e-02</td>\n",
       "      <td>4.26308662e-02</td>\n",
       "      <td>3.78118306e-02</td>\n",
       "      <td>6.95859119e-02</td>\n",
       "      <td>-4.20008637e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.98840415e-02</td>\n",
       "      <td>1.64022837e-02</td>\n",
       "      <td>-4.90665212e-02</td>\n",
       "      <td>4.81191762e-02</td>\n",
       "      <td>-9.69780684e-02</td>\n",
       "      <td>-1.16978601e-01</td>\n",
       "      <td>1.07039817e-01</td>\n",
       "      <td>2.18950473e-02</td>\n",
       "      <td>4.59282361e-02</td>\n",
       "      <td>-6.05028607e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.86743562e-02</td>\n",
       "      <td>1.04232021e-02</td>\n",
       "      <td>1.38152717e-02</td>\n",
       "      <td>-5.32790925e-03</td>\n",
       "      <td>-1.77161284e-02</td>\n",
       "      <td>1.04324900e-01</td>\n",
       "      <td>9.65044126e-02</td>\n",
       "      <td>7.19451010e-02</td>\n",
       "      <td>1.72711313e-02</td>\n",
       "      <td>6.24693604e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.30832557e-03</td>\n",
       "      <td>6.94514960e-02</td>\n",
       "      <td>9.17118881e-03</td>\n",
       "      <td>-4.25593607e-04</td>\n",
       "      <td>3.68529968e-02</td>\n",
       "      <td>2.88750455e-02</td>\n",
       "      <td>9.93606523e-02</td>\n",
       "      <td>1.99077209e-03</td>\n",
       "      <td>3.11414283e-02</td>\n",
       "      <td>3.83325480e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.25946605e-02</td>\n",
       "      <td>-3.91616262e-02</td>\n",
       "      <td>1.23729361e-02</td>\n",
       "      <td>-2.83677857e-02</td>\n",
       "      <td>-8.51575360e-02</td>\n",
       "      <td>7.25132674e-02</td>\n",
       "      <td>6.53430074e-02</td>\n",
       "      <td>2.26758630e-03</td>\n",
       "      <td>6.07209243e-02</td>\n",
       "      <td>-2.46002264e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.41132241e-02</td>\n",
       "      <td>7.76526034e-02</td>\n",
       "      <td>-8.35783686e-03</td>\n",
       "      <td>2.37053819e-02</td>\n",
       "      <td>5.61783165e-02</td>\n",
       "      <td>3.36992592e-02</td>\n",
       "      <td>1.19458653e-01</td>\n",
       "      <td>-2.01092865e-02</td>\n",
       "      <td>3.62723432e-02</td>\n",
       "      <td>4.82863858e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.69673532e-02</td>\n",
       "      <td>1.13059739e-02</td>\n",
       "      <td>-1.16295973e-02</td>\n",
       "      <td>-2.42045093e-02</td>\n",
       "      <td>-5.78260906e-02</td>\n",
       "      <td>3.89332138e-02</td>\n",
       "      <td>1.18804961e-01</td>\n",
       "      <td>-2.96259206e-02</td>\n",
       "      <td>3.69524844e-02</td>\n",
       "      <td>-9.53654386e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.86128864e-02</td>\n",
       "      <td>-2.58876905e-02</td>\n",
       "      <td>3.46109122e-02</td>\n",
       "      <td>5.58277592e-02</td>\n",
       "      <td>-3.87978852e-02</td>\n",
       "      <td>-5.56877032e-02</td>\n",
       "      <td>1.44394651e-01</td>\n",
       "      <td>2.46080924e-02</td>\n",
       "      <td>-7.19921589e-02</td>\n",
       "      <td>-4.99793142e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.83698123e-02</td>\n",
       "      <td>-3.49769071e-02</td>\n",
       "      <td>-2.14673597e-02</td>\n",
       "      <td>1.45020243e-02</td>\n",
       "      <td>5.76726533e-02</td>\n",
       "      <td>3.32759731e-02</td>\n",
       "      <td>1.09838024e-01</td>\n",
       "      <td>-7.57560134e-02</td>\n",
       "      <td>2.23050658e-02</td>\n",
       "      <td>-4.70947437e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Embedding1_0     Embedding1_1     Embedding1_2     Embedding1_3  \\\n",
       "0  -9.81967244e-03   1.01662287e-02   3.75229940e-02   1.75703913e-02   \n",
       "1   5.98840415e-02   1.64022837e-02  -4.90665212e-02   4.81191762e-02   \n",
       "2   6.30832557e-03   6.94514960e-02   9.17118881e-03  -4.25593607e-04   \n",
       "3  -1.41132241e-02   7.76526034e-02  -8.35783686e-03   2.37053819e-02   \n",
       "4  -7.86128864e-02  -2.58876905e-02   3.46109122e-02   5.58277592e-02   \n",
       "\n",
       "      Embedding1_4     Embedding1_5    Embedding1_6     Embedding1_7  \\\n",
       "0  -1.11436069e-01   3.83325890e-02  1.48906738e-01   4.44466770e-02   \n",
       "1  -9.69780684e-02  -1.16978601e-01  1.07039817e-01   2.18950473e-02   \n",
       "2   3.68529968e-02   2.88750455e-02  9.93606523e-02   1.99077209e-03   \n",
       "3   5.61783165e-02   3.36992592e-02  1.19458653e-01  -2.01092865e-02   \n",
       "4  -3.87978852e-02  -5.56877032e-02  1.44394651e-01   2.46080924e-02   \n",
       "\n",
       "      Embedding1_8     Embedding1_9  ...  Embedding1_374   Embedding1_375  \\\n",
       "0   5.77533916e-02  -1.21526700e-02  ...  6.11344092e-02   1.98782869e-02   \n",
       "1   4.59282361e-02  -6.05028607e-02  ...  4.86743562e-02   1.04232021e-02   \n",
       "2   3.11414283e-02   3.83325480e-02  ...  2.25946605e-02  -3.91616262e-02   \n",
       "3   3.62723432e-02   4.82863858e-02  ...  6.69673532e-02   1.13059739e-02   \n",
       "4  -7.19921589e-02  -4.99793142e-02  ...  2.83698123e-02  -3.49769071e-02   \n",
       "\n",
       "    Embedding1_376   Embedding1_377   Embedding1_378  Embedding1_379  \\\n",
       "0   1.33477971e-02   3.86779606e-02  -4.79677059e-02  3.42200510e-02   \n",
       "1   1.38152717e-02  -5.32790925e-03  -1.77161284e-02  1.04324900e-01   \n",
       "2   1.23729361e-02  -2.83677857e-02  -8.51575360e-02  7.25132674e-02   \n",
       "3  -1.16295973e-02  -2.42045093e-02  -5.78260906e-02  3.89332138e-02   \n",
       "4  -2.14673597e-02   1.45020243e-02   5.76726533e-02  3.32759731e-02   \n",
       "\n",
       "   Embedding1_380   Embedding1_381  Embedding1_382   Embedding1_383  \n",
       "0  4.26308662e-02   3.78118306e-02  6.95859119e-02  -4.20008637e-02  \n",
       "1  9.65044126e-02   7.19451010e-02  1.72711313e-02   6.24693604e-03  \n",
       "2  6.53430074e-02   2.26758630e-03  6.07209243e-02  -2.46002264e-02  \n",
       "3  1.18804961e-01  -2.96259206e-02  3.69524844e-02  -9.53654386e-03  \n",
       "4  1.09838024e-01  -7.57560134e-02  2.23050658e-02  -4.70947437e-02  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings1_df = pd.concat(\n",
    "    [embeddings1_df[c].apply(pd.Series).add_prefix(c + \"_\") for c in embeddings1_df], axis=1\n",
    ")\n",
    "\n",
    "embeddings1_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1_df = embeddings1_df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Generate Distance Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "def generate_distance_matrix(df : pd.DataFrame,\n",
    "                distance_metric : str = \"euclidean\") -> pd.DataFrame: # 2.5k x 2.5k\n",
    "    if distance_metric == \"manhattan\":\n",
    "        p = 1\n",
    "    elif distance_metric == \"euclidean\":\n",
    "        p = 2\n",
    "    elif distance_metric == \"chebychev\":\n",
    "        p = math.inf\n",
    "    else:\n",
    "        p = 2\n",
    "    dis_matrix = distance_matrix(df.values, df.values, p)\n",
    "    dis_df = pd.DataFrame(dis_matrix)\n",
    "    return dis_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Generate Dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict(df_dist: pd.DataFrame,\n",
    "                threshold: float) -> dict:\n",
    "    filt = (df_dist[:] > threshold)\n",
    "    df_filt = df_dist.copy()\n",
    "    df_filt[filt] = np.nan\n",
    "    dict_dist = df_filt.to_dict('dict')\n",
    "    for i, dic in dict_dist.items():\n",
    "        to_pop = list()\n",
    "        for key, value in dic.items():\n",
    "            if np.isnan(value):\n",
    "                to_pop.append(key)\n",
    "        for target_key in to_pop:\n",
    "            dic.pop(target_key)\n",
    "        dict_dist[i] = dic\n",
    "    return dict_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict_match(dict_dist: dict) -> dict:   \n",
    "    dict_match = dict()\n",
    "\n",
    "    for key, value in dict_dist.items():\n",
    "        for sub_key in value.keys():\n",
    "            if dict_symptom[key] not in dict_match:\n",
    "                dict_match[dict_symptom[key]] = [dict_symptom[sub_key]]\n",
    "            else:\n",
    "                dict_match[dict_symptom[key]] = [*dict_match.get(dict_symptom[key]), dict_symptom[sub_key]]\n",
    "\n",
    "    return dict_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_symptoms_df = pd.read_csv(\"../output/activities_symptoms_bool.csv\")\n",
    "activities_symptoms_df.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_sym = (activities_symptoms_df[\"is_symptom\"] == 1)\n",
    "filt_sym_df = activities_symptoms_df[filt_sym]\n",
    "filt_sym_list = filt_sym_df[\"symptomName\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_not_act = (activities_symptoms_df[\"is_activity\"] == 0)\n",
    "filt_not_act_df = activities_symptoms_df[filt_not_act]\n",
    "filt_not_act_list = filt_not_act_df[\"symptomName\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_sym(dict_dist):  \n",
    "    dict_sym = dict()\n",
    "\n",
    "    for sym, list_sym in dict_dist.items():\n",
    "        if sym not in filt_sym_list:\n",
    "            continue\n",
    "        for sub_sym in list_sym:\n",
    "            if sub_sym in filt_not_act_list:\n",
    "                continue\n",
    "            if sym not in dict_sym:\n",
    "                dict_sym[sym] = [sub_sym]\n",
    "            else:\n",
    "                dict_sym[sym] = [*dict_sym.get(sym), sub_sym]\n",
    "    \n",
    "    return dict_sym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Distance Matrix and Dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist_1 = generate_distance_matrix(embeddings1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dist_086 = generate_dict(df_dist_1, 0.86)\n",
    "dict_086 = generate_dict_match(dict_dist_086)\n",
    "dict_086_sym = create_dict_sym(dict_086)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDBSCAN* Clustering:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more for DS research rather than the MVP functionality. The quality of the matching mostly seems to rely on the word embeddings, in any case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting With Different Parameters and Attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, -1}\n"
     ]
    }
   ],
   "source": [
    "clusterer_distance = hdbscan.HDBSCAN(metric='precomputed')\n",
    "clusterer_distance.fit(df_dist_1)\n",
    "print(set(clusterer_distance.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, -1}\n"
     ]
    }
   ],
   "source": [
    "clusterer_distance = hdbscan.HDBSCAN(min_samples=4, min_cluster_size=5, metric='precomputed')\n",
    "clusterer_distance.fit(df_dist_1)\n",
    "print(set(clusterer_distance.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404\n",
      "{0.0, 1.0, 0.98305244711713, 0.9791146416423028, 0.9769353926578465, 0.9961216827029399, 0.9738910081588747, 0.9970175222727984, 0.9902114067769573, 0.9720453152121288, 0.972016389330309}\n"
     ]
    }
   ],
   "source": [
    "print(len(clusterer_distance.probabilities_))\n",
    "print(set(clusterer_distance.probabilities_[::20]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels and probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abcess\n",
      "-1\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(dict_symptom[0])\n",
    "print(clusterer_distance.labels_[0])\n",
    "print(clusterer_distance.probabilities_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdomen\n",
      "6\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(dict_symptom[1])\n",
    "print(clusterer_distance.labels_[1])\n",
    "print(clusterer_distance.probabilities_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stomach\n",
      "6\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(dict_symptom[1594])\n",
    "print(clusterer_distance.labels_[1594])\n",
    "print(clusterer_distance.probabilities_[1594])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_6 = {\n",
    "    \"indices\": [],\n",
    "    \"probabilities\": []\n",
    "}\n",
    "for i, label in enumerate(clusterer_distance.labels_):\n",
    "    if label == 6:\n",
    "        label_6[\"indices\"].append(i)\n",
    "        label_6[\"probabilities\"].append(clusterer_distance.probabilities_[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_label_6 = list()\n",
    "\n",
    "for i, index in enumerate(label_6[\"indices\"]):\n",
    "    if label_6[\"probabilities\"][i] < 1.0:\n",
    "        soft_label_6.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soft_label_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antimalaria\n",
      "6\n",
      "0.9739849522332443\n"
     ]
    }
   ],
   "source": [
    "print(dict_symptom[181])\n",
    "print(clusterer_distance.labels_[181])\n",
    "print(clusterer_distance.probabilities_[181])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_label_6 = list()\n",
    "\n",
    "for i, index in enumerate(label_6[\"indices\"]):\n",
    "    if label_6[\"probabilities\"][i] == 1.0:\n",
    "        hard_label_6.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "813"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_label_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_6[\"indices\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to further refine/reduce number of matches by taking the probabilities value into account."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Cluster Function:\n",
    "\n",
    "The function must therefore run the HDBSCAN clustering algorithm and return a dictionary where the label groups are returned. min_sample and min_cluster_size should be parameters input into the function to quickly receive different results.\n",
    "\n",
    "If we want, we can include parameter to make a decision whether to use hard/soft clustering filter, and at what threshold. Implementing this would help further refining the matches in case too many labels with too many items included are generated.\n",
    "\n",
    "Return a dict of matches and also a list of outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(df_dist: pd.DataFrame, min_sample_n: int = 5, \n",
    "                min_cluster_n: int = 5, filter: bool = False,\n",
    "                min_probability: float = 1.0) -> dict:\n",
    "    clusterer_distance = hdbscan.HDBSCAN(\n",
    "        min_samples = min_sample_n, \n",
    "        min_cluster_size = min_cluster_n, \n",
    "        metric='precomputed')\n",
    "    clusterer_distance.fit(df_dist)\n",
    "\n",
    "    # create a dictionary:\n",
    "    # a key for each label, value are indices\n",
    "\n",
    "    labels = list(set(clusterer_distance.labels_))\n",
    "\n",
    "    label_dict = dict()\n",
    "\n",
    "    for label in labels:\n",
    "        label_dict[label] = {}\n",
    "\n",
    "    for i, assigned_label in enumerate(clusterer_distance.labels_):\n",
    "        label_dict[assigned_label][i] = clusterer_distance.probabilities_[i]\n",
    "    \n",
    "    # create a dictionary:\n",
    "    # keys are indices from 0 to end, values are all indices from \n",
    "    # the same label\n",
    "\n",
    "    match_dict = dict()\n",
    "    outliers = list()\n",
    "\n",
    "    for i in range(len(clusterer_distance.labels_)):\n",
    "        for label, label_group in label_dict.items():\n",
    "            if label == -1 and i in label_group:\n",
    "                outliers.append(i)\n",
    "                continue\n",
    "            if i in label_group:\n",
    "                match_dict[i] = label_group\n",
    "\n",
    "    return match_dict, outliers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict, outliers, labels = cluster(df_dist_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, -1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(outliers))\n",
    "outliers[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary containing similar values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {1: 1.0, 6: 0.9796693383722548, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 25: 0.9645519056822113, 27: 0.9605620807...\n"
     ]
    }
   ],
   "source": [
    "print(str(cluster_dict)[:200] + \"...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out different values:\n",
    "\n",
    "We have 422 symptoms in our symptom list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filt_sym_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict, outliers, labels = cluster(df_dist_1, min_sample_n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, -1]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 7, 26, 28, 29]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(outliers))\n",
    "outliers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2068\n",
      "{1: {1: 1.0, 2: 1.0, 3: 1.0, 4: 0.9307565897715478, 5: 1.0, 6: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.98...\n"
     ]
    }
   ],
   "source": [
    "print(len(cluster_dict[2]))\n",
    "print(str(cluster_dict)[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = cluster(df_dist_1, min_sample_n = 1)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = cluster(df_dist_1, min_sample_n = 3,\n",
    "            min_cluster_n = 4)\n",
    "len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the lowest we can go for min sample and min cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = cluster(df_dist_1, min_sample_n = 1,\n",
    "            min_cluster_n = 2)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {1: 1.0, 1550: 0.9479793910211823, 1594: 1.0}, 2: {2: 1.0, 1328: 1.0}, 3: {3: 1.0, 2097: 1.0}, 5: {5: 1.0, 6: 1.0, 1329: 0.8907824978608478}, 6: {5: 1.0, 6: 1.0, 1329: 0.8907824978608478}, 8: {8: ...\n"
     ]
    }
   ],
   "source": [
    "print(str(cluster_dict)[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sym_dict = generate_dict_match(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abdomen': ['Abdomen', 'Stomachic', 'Stomach'], 'Abortifacient': ['Abortifacient', 'Preventitive(Abortifacient)'], 'Abortive': ['Abortive', 'Abortive?'], 'Abscess': ['Abscess', 'Abscess(Breast)', 'Pr...\n"
     ]
    }
   ],
   "source": [
    "print(str(cluster_sym_dict)[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = create_dict_sym(cluster_sym_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "{'Acne': ['Acne', 'Pimple'], 'Alcoholism': ['Alcoholism', 'Drunkenness'], 'Allergy': ['Allergenic', 'Allergy'], 'Amblyopia': ['Amblyopia', 'Nyctalopia'], 'Amnesia': ['Amnesia', 'Dementia', 'Forgetfuln...\n"
     ]
    }
   ],
   "source": [
    "print(len(final))\n",
    "print(str(final)[:200] + \"...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison With Dictionary Generated With Distance Matrix and Distance Threshold:\n",
    "\n",
    "The dictionaries generated with HDBSCAN* are much more restrictive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Acne', ['Acne', 'Pimple']),\n",
       " ('Alcoholism', ['Alcoholism', 'Beer', 'Beverage', 'Drunkenness']),\n",
       " ('Allergy', ['Allergenic', 'Allergy']),\n",
       " ('Amblyopia', ['Amblyopia']),\n",
       " ('Amenorrhea', ['Amenorrhea'])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dict_086_sym))\n",
    "list(dict_086_sym.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['Sore(Eye)', 'Ache(Eye)']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Abdominal pain\" in final.keys())\n",
    "print(final[\"Eye pain\"])\n",
    "print(\"Common cold\" in final.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abdomen', 'Ache(Stomach)', 'Cancer(Abdomen)']\n",
      "['Eye', 'Eye drop', 'Sore(Eye)', 'Ache(Eye)']\n",
      "['Cold']\n"
     ]
    }
   ],
   "source": [
    "print(dict_086_sym[\"Abdominal pain\"])\n",
    "print(dict_086_sym[\"Eye pain\"])\n",
    "print(dict_086_sym[\"Common cold\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not as useful, so we will explore more options provided by the HDBSCAN* library in hopes of creating more appropriate clusters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Function with Leaf Clustering:\n",
    "From the HDBSCAN* documentation:\n",
    "\n",
    "\"_HDBSCAN supports an extra parameter_ cluster_selection_method _to determine how it selects flat clusters from the cluster tree hierarchy. The default method is 'eom' for Excess of Mass, the algorithm described in How HDBSCAN Works. This is not always the most desireable approach to cluster selection. If you are more interested in having small homogeneous clusters then you may find Excess of Mass has a tendency to pick one or two large clusters and then a number of small extra clusters. In this situation you may be tempted to recluster just the data in the single large cluster. Instead, a better option is to select 'leaf' as a cluster selection method. This will select leaf nodes from the tree, producing many small homogeneous clusters. Note that you can still get variable density clusters via this method, and it is also still possible to get large clusters, but there will be a tendency to produce a more fine grained clustering than Excess of Mass can provide._\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_cluster(df_dist: pd.DataFrame, min_sample_n: int = 5, \n",
    "                min_cluster_n: int = 5, filter: bool = False,\n",
    "                min_probability: float = 1.0) -> dict:\n",
    "    clusterer_distance = hdbscan.HDBSCAN(\n",
    "        min_samples = min_sample_n, \n",
    "        min_cluster_size = min_cluster_n, \n",
    "        cluster_selection_method = 'leaf',\n",
    "        metric='precomputed')\n",
    "    clusterer_distance.fit(df_dist)\n",
    "\n",
    "    # create a dictionary:\n",
    "    # a key for each label, value are indices\n",
    "\n",
    "    labels = list(set(clusterer_distance.labels_))\n",
    "\n",
    "    label_dict = dict()\n",
    "\n",
    "    for label in labels:\n",
    "        label_dict[label] = {}\n",
    "\n",
    "    for i, assigned_label in enumerate(clusterer_distance.labels_):\n",
    "        label_dict[assigned_label][i] = clusterer_distance.probabilities_[i]\n",
    "    \n",
    "    # create a dictionary:\n",
    "    # keys are indices from 0 to end, values are all indices from \n",
    "    # the same label\n",
    "\n",
    "    match_dict = dict()\n",
    "    outliers = list()\n",
    "\n",
    "    for i in range(len(clusterer_distance.labels_)):\n",
    "        for label, label_group in label_dict.items():\n",
    "            if label == -1 and i in label_group:\n",
    "                outliers.append(i)\n",
    "                continue\n",
    "            if i in label_group:\n",
    "                match_dict[i] = label_group\n",
    "\n",
    "    return match_dict, outliers, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, previous results:\n",
    "\n",
    "* 559 labels\n",
    "* 835 outliers\n",
    "* 255 symptoms matched to activities in the final dictionary\n",
    "* \"Abdominal pain\", \"Common cold\" not included amongst others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575 labels\n",
      "863 outliers\n",
      "249 symptoms matched to activities in the final dictionary \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Acne', ['Acne', 'Pimple']),\n",
       " ('Alcoholism', ['Alcoholism', 'Drunkenness']),\n",
       " ('Allergy', ['Allergenic', 'Allergy']),\n",
       " ('Amblyopia', ['Amblyopia', 'Nyctalopia']),\n",
       " ('Amnesia', ['Amnesia', 'Dementia', 'Forgetfulness', 'Memory'])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = leaf_cluster(df_dist_1, min_sample_n = 1,\n",
    "            min_cluster_n = 2)\n",
    "print(len(labels), \"labels\")\n",
    "print(len(outliers), \"outliers\")\n",
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict), \"symptoms matched to activities in the final dictionary \")\n",
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['Sore(Eye)', 'Ache(Eye)']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(final_cluster_dict[\"Eye pain\"])\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look at the dictionary containing all label groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abdomen', ['Abdomen', 'Stomachic', 'Stomach']),\n",
       " ('Abortifacient', ['Abortifacient', 'Preventitive(Abortifacient)']),\n",
       " ('Abortive', ['Abortive', 'Abortive?']),\n",
       " ('Abscess', ['Abscess', 'Abscess(Breast)', 'Preventitive(Abscess)']),\n",
       " ('Abscess(Breast)', ['Abscess', 'Abscess(Breast)', 'Preventitive(Abscess)'])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "list(cluster_sym_dict.items())[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for leaf clustering are overall quite similar: while a few more labels were created, and less data points labelled as outliers, the dictionary matching only to symptoms actually ended up containing a few less entries. \"Common cold\" and \"Abdominal pain\" are still not included."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Function with Soft Clustering:\n",
    "\n",
    "It is important to note that, if we wish to use the soft clustering we should use the prediction_data=True option for HDBSCAN. This will ensure we generate the extra data required that will allow soft clustering to work. This __cannot__ generate prediction data for non-vectorspace inputs - access to the source data rather than mere distances is required!\n",
    "\n",
    "Accordingly, we should use the original embeddings dataframe and likewise remove the metric = 'precomputed' parameter:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    clusterer_distance = hdbscan.HDBSCAN(\n",
    "        min_samples = 1, \n",
    "        min_cluster_size = 2, \n",
    "        prediction_data= True)\n",
    "    clusterer_distance.fit(df_dist_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no -1 outliers label, so one less than .labels_ returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Clustering Function:\n",
    "\n",
    "For each list in soft clusters: \n",
    "\n",
    "* label is argmax \n",
    "\n",
    "* if the value at argmax index position is above threshold => add to label group\n",
    "\n",
    "* below threshold: add to outlier dictionary, but label as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_cluster(df_vect: pd.DataFrame, min_sample_n: int = 5, \n",
    "                min_cluster_n: int = 5, threshold: float = 0.2025,\n",
    "                filter: bool = False,\n",
    "                min_probability: float = 1.0) -> dict:\n",
    "\n",
    "    threshold = threshold / 100\n",
    "\n",
    "    clusterer_distance = hdbscan.HDBSCAN(\n",
    "        min_samples = min_sample_n, \n",
    "        min_cluster_size = min_cluster_n, \n",
    "        prediction_data= True)\n",
    "\n",
    "    clusterer_distance.fit(df_vect)\n",
    "\n",
    "    soft_clusters = hdbscan.all_points_membership_vectors(clusterer_distance)\n",
    "\n",
    "    # create a dictionary:\n",
    "    # a key for each label, value are indices\n",
    "\n",
    "    labels = range(len(soft_clusters[0]))\n",
    "\n",
    "    label_dict = dict()\n",
    "    label_dict[-1] = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_dict[label] = {}\n",
    "\n",
    "    for i, membership_vectors in enumerate(soft_clusters):\n",
    "        assigned_label = np.argmax(membership_vectors)\n",
    "        membership_vector = membership_vectors[assigned_label]\n",
    "        if membership_vector >= threshold:\n",
    "            label_dict[assigned_label][i] = membership_vector\n",
    "        else:\n",
    "            label_dict[-1][i] = {assigned_label: membership_vector}\n",
    "    \n",
    "    # create a dictionary:\n",
    "    # keys are indices from 0 to end, values are all indices from \n",
    "    # the same label\n",
    "\n",
    "    match_dict = dict()\n",
    "    outliers = list()\n",
    "\n",
    "    for i in range(len(soft_clusters)):\n",
    "        for label, label_group in label_dict.items():\n",
    "            if label == -1 and i in label_group:\n",
    "                outliers.append(label_group)\n",
    "                continue\n",
    "            if i in label_group:\n",
    "                match_dict[i] = label_group\n",
    "\n",
    "    return match_dict, outliers, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For verification purposes, we are using the basic threshold and trying with distance matrix to check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/TechLabs/TL-WT22_DataScience/.venv/lib/python3.8/site-packages/hdbscan/prediction.py:645: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  in_cluster_probs = all_points_prob_in_some_cluster(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = soft_cluster(df_dist_1, min_sample_n = 1,\n",
    "            min_cluster_n = 2)\n",
    "print(len(labels))\n",
    "print(len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: {279: 0.0015467320559012343}, 6: {0: 0.0}, 7: {270: 0.0006325716607575951}, 25: {115: 0.0018285710047903538}, 26: {74: 0.0014173188180648247}, 39: {65: 0.0012295304792319943}, 55: {29: 0.00121941...\n"
     ]
    }
   ],
   "source": [
    "print(str(outliers)[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Acne', ['Acne', 'Pimple']),\n",
       " ('Alcoholism', ['Alcoholism', 'Drowning', 'Drunkenness']),\n",
       " ('Allergy', ['Allergy', 'Emphysema']),\n",
       " ('Amblyopia', ['Amblyopia', 'Nyctalopia', 'Nypnotic']),\n",
       " ('Amenorrhea', ['Amenorrhea', 'Enteritis', 'Enterosis', 'Enterostenosis'])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict))\n",
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(\"Eye pain\" in final_cluster_dict.keys())\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glaucoma']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cluster_dict[\"Eye pain\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results seem somewhat promising (reduction in outliers), but the matches seem a little scrambled. However, this test run used a distance matrix as input, which should have caused issues. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Embeddings Dataframe for Soft Clustering:\n",
    "\n",
    "##### Default Threshold: \n",
    "\n",
    "For now, using the default threshold again (which is a little lower than the max membership value discovered amongst previous outliers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/TechLabs/TL-WT22_DataScience/.venv/lib/python3.8/site-packages/hdbscan/prediction.py:645: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  in_cluster_probs = all_points_prob_in_some_cluster(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 labels\n",
      "1865 outliers\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = soft_cluster(embeddings1_df, min_sample_n = 1,\n",
    "            min_cluster_n = 2)\n",
    "print(len(labels), \"labels\")\n",
    "print(len(outliers), \"outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: {23: 0.0015456918900324888}, 1: {506: 0.002015968949266312}, 4: {76: 0.0014027082077308775}, 5: {400: 0.0020198751979227762}, 7: {260: 0.0014376918096444334}, 8: {225: 0.00195581615208487}, 9: {5...\n"
     ]
    }
   ],
   "source": [
    "print(str(outliers)[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 symptoms matched in the symptom-activity dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Anxiety', ['Anxiety']),\n",
       " ('Arthritis', ['Arthritis', 'Arthritis?']),\n",
       " ('Asthma', ['Asthma', 'Bronchial-Asthma']),\n",
       " ('Ataxia', ['Ataxia', 'Ataxia(Locomotor)']),\n",
       " ('Bronchitis', ['Bronchitis', 'Bronchosis'])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict), \"symptoms matched in the symptom-activity dictionary\")\n",
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(\"Eye pain\" in final_cluster_dict.keys())\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threshold 0.202:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/TechLabs/TL-WT22_DataScience/.venv/lib/python3.8/site-packages/hdbscan/prediction.py:645: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  in_cluster_probs = all_points_prob_in_some_cluster(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 labels\n",
      "1853 outliers\n",
      "64 symptoms matched in the symptom-activity dictionary\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = soft_cluster(embeddings1_df, min_sample_n = 1,\n",
    "            min_cluster_n = 2, threshold = 0.202)\n",
    "print(len(labels), \"labels\")\n",
    "print(len(outliers), \"outliers\")\n",
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict), \"symptoms matched in the symptom-activity dictionary\")\n",
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(\"Eye pain\" in final_cluster_dict.keys())\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anxiety', ['Anxiety']),\n",
       " ('Arthritis', ['Arthritis', 'Arthritis?']),\n",
       " ('Asthma', ['Asthma', 'Bronchial-Asthma']),\n",
       " ('Ataxia', ['Ataxia', 'Ataxia(Locomotor)']),\n",
       " ('Bronchitis', ['Bronchitis', 'Bronchosis'])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threshold 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/TechLabs/TL-WT22_DataScience/.venv/lib/python3.8/site-packages/hdbscan/prediction.py:645: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  in_cluster_probs = all_points_prob_in_some_cluster(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 labels\n",
      "123 outliers\n",
      "380 symptoms matched in the symptom-activity dictionary\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = soft_cluster(embeddings1_df, min_sample_n = 1,\n",
    "            min_cluster_n = 2, threshold = 0.1)\n",
    "print(len(labels), \"labels\")\n",
    "print(len(outliers), \"outliers\")\n",
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict), \"symptoms matched in the symptom-activity dictionary\")\n",
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(\"Eye pain\" in final_cluster_dict.keys())\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Acne', ['Acne', 'Lacrimatory', 'Mastitis']),\n",
       " ('Alcoholism', ['Alcoholism', 'Drunkenness', 'Home-Remedy']),\n",
       " ('Allergy', ['Allergy', 'Fumigant']),\n",
       " ('Amblyopia',\n",
       "  ['Amblyopia', 'Deafness', 'Laryngalgia', 'Laryngeal', 'Laryngitis']),\n",
       " ('Amenorrhea', ['Amenorrhea', 'Sponge'])]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dentifrice',\n",
       " 'Dentition',\n",
       " 'Denture',\n",
       " 'Medicine (Vet)',\n",
       " 'Respiratory',\n",
       " 'Rope',\n",
       " 'Tongue',\n",
       " 'Toothstick',\n",
       " 'Pockmark',\n",
       " 'Mucus-Mover',\n",
       " 'Scleroderma']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cluster_dict[\"Common cold\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this threshold, we have an acceptable amount of symptoms matched to activities as recorded in Dr. Duke's database, however they are much too broad and their relation sometimes seems far fetched."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threshold 0.15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/TechLabs/TL-WT22_DataScience/.venv/lib/python3.8/site-packages/hdbscan/prediction.py:645: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  in_cluster_probs = all_points_prob_in_some_cluster(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 labels\n",
      "472 outliers\n",
      "323 symptoms matched in the symptom-activity dictionary\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cluster_dict, outliers, labels = soft_cluster(embeddings1_df, min_sample_n = 1,\n",
    "            min_cluster_n = 2, threshold = 0.15)\n",
    "print(len(labels), \"labels\")\n",
    "print(len(outliers), \"outliers\")\n",
    "cluster_sym_dict = generate_dict_match(cluster_dict)\n",
    "final_cluster_dict = create_dict_sym(cluster_sym_dict)\n",
    "print(len(final_cluster_dict), \"symptoms matched in the symptom-activity dictionary\")\n",
    "print(\"Abdominal pain\" in final_cluster_dict.keys())\n",
    "print(\"Eye pain\" in final_cluster_dict.keys())\n",
    "print(\"Common cold\" in final_cluster_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Acne', ['Acne', 'Lacrimatory', 'Mastitis']),\n",
       " ('Alcoholism', ['Alcoholism', 'Drunkenness', 'Home-Remedy']),\n",
       " ('Allergy', ['Allergy', 'Fumigant']),\n",
       " ('Amblyopia',\n",
       "  ['Amblyopia', 'Deafness', 'Laryngalgia', 'Laryngeal', 'Laryngitis']),\n",
       " ('Amnesia', ['Amnesia', 'Forgetfulness'])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_cluster_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dentifrice',\n",
       " 'Dentition',\n",
       " 'Denture',\n",
       " 'Medicine (Vet)',\n",
       " 'Respiratory',\n",
       " 'Rope',\n",
       " 'Tongue',\n",
       " 'Toothstick',\n",
       " 'Pockmark',\n",
       " 'Scleroderma']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cluster_dict[\"Common cold\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soft clustering results continue to seem disappointing. While the length of the final dictionary is alright, and certain matches seem promising, aberrant matches such as \"Abdominal pain\" matching to \"Ankle\" continue to be present and cast a shadow of doubt over the results in total."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Ahead:\n",
    "\n",
    "The final notebook will deal with visualising the data we have and hopefully yield some more insights into why the clusters sometimes seem so mismatched."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a29d814ff9867b1bca3070bc77419176db06fa129a33d01f96cbf77dd5fcb2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
