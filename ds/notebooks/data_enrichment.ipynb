{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaturDoc - TL BL WT 22-23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data enrichment:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_duke_df = pd.read_csv(\"../data/DUKE/PIVOT_ETHNOBOT.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KEW:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _Note: reduced and pivoted WCVP datasets:_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the data_transformation notebook, some of the csv files were too large to be uploaded to Github. By creating a copy of wcvp_distribution.csv and wcvp_names.csv containing only columns that were useful to us and by pivoting the entire table, the number of rows and columns was reduced significantly for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df = pd.read_csv(\"../data/WCVP/STR_REDUCED_PIVOT_wcvp_distribution.csv\", sep=\",\")\n",
    "names_df = pd.read_csv(\"../data/WCVP/REDUCED_wcvp_names.csv\", sep=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHO Monographs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_01_pdf = open('../data/WHO/monograph_01.pdf', 'rb')\n",
    "\n",
    "who_01_reader = PyPDF2.PdfReader(who_01_pdf)\n",
    "\n",
    "who_01_pages = list()\n",
    "\n",
    "pattern_fi = re.compile(\"ﬁ\")\n",
    "pattern_fl = re.compile(\"ﬂ\")\n",
    "pattern_minus = re.compile(\"–\")\n",
    "pattern_brackets = re.compile(\"\\([\\s0-9,-]+\\)\")\n",
    "pattern_spacedot = re.compile(\" \\.\")\n",
    "pattern_spacecomma = re.compile(\" ,\")\n",
    "pattern_spacequotesingle = re.compile(\" ’\")\n",
    "pattern_spacequotedouble = re.compile(\" ”\")\n",
    "pattern_doublespace = re.compile(\"\\s\\s+\")\n",
    "pattern_dashspace = re.compile(\"-\\s+\")\n",
    "  \n",
    "for page in range(len(who_01_reader.pages)):\n",
    "    page_obj = who_01_reader.pages[page]\n",
    "    text = page_obj.extract_text()\n",
    "    text = re.sub(pattern_fi, \"fi\", text)\n",
    "    text = re.sub(pattern_fl, \"fl\", text)\n",
    "    text = re.sub(pattern_minus, \"-\", text)\n",
    "    text = re.sub(pattern_brackets, \"\", text)\n",
    "    text = re.sub(pattern_spacedot, \".\", text)\n",
    "    text = re.sub(pattern_spacecomma, \",\", text)\n",
    "    text = re.sub(pattern_spacequotesingle, \"’\", text)\n",
    "    text = re.sub(pattern_spacequotedouble, \"”\", text)\n",
    "    text = re.sub(pattern_doublespace, \" \", text)\n",
    "    text = re.sub(pattern_dashspace, \"\", text)\n",
    "    lines = text.split(\"\\n\")\n",
    "    who_01_pages.append(lines)\n",
    "    \n",
    "who_01_pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_01_50 = who_01_pages[7 : 57]\n",
    "p_51_58 = who_01_pages[75 : 83]\n",
    "p_59_60 = who_01_pages[57 : 59]\n",
    "p_61_66 = who_01_pages[69 : 75]\n",
    "p_67_76 = who_01_pages[59 : 69]\n",
    "p_77_end = who_01_pages[83 : ]\n",
    "\n",
    "who_01_pages_corrected = p_01_50 + p_51_58 + p_59_60 + p_61_66 + p_67_76 + p_77_end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching the Duke dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duke_names = mod_duke_df[\"TAXON\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_formula = re.compile(r\"\\.[A-Za-z0-9]+.*\")\n",
    "\n",
    "# Definitions with in-keyword:\n",
    "\n",
    "who_01_def = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[3:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Definition\" in line:\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"Synonyms\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            who_01_def.append(\" \".join(page[i + 1 : i + n_lines]))\n",
    "\n",
    "# Vernacular names with in-keyword:\n",
    "\n",
    "who_01_vernacular = list()\n",
    "reg_pattern = re.compile(r\"\\.\")\n",
    "  \n",
    "for page in who_01_pages_corrected[3:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Selected vernacular names\" in line:\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"Description\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "            \n",
    "            output =  output.replace(\".\", \",\")\n",
    "            \n",
    "            # Sometimes taxonomic names appear in the WHO document names as a header of sorts:\n",
    "            for name in duke_names:\n",
    "                output = output.replace(name, \",\")\n",
    "            \n",
    "            output =  output.replace(\", \", \",\")\n",
    "\n",
    "            who_01_vernacular.append(output)\n",
    "\n",
    "# Clinical medicine with in-keyword:\n",
    "\n",
    "who_01_clinical = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[3:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Uses supported by clinical data\" in line:\n",
    "            n_lines = 1\n",
    "            while \"Uses described in pharmacopoeias and in traditional\" not in page[i + n_lines] and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            # in case the description gets cut off, drop the incomplete sentence:\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "            \n",
    "            who_01_clinical.append(output)\n",
    "\n",
    "# Traditional medicine with in-keyword:\n",
    "\n",
    "who_01_traditional = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[3:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Uses described in pharmacopoeias and in traditional\" in line:\n",
    "            n_lines = 2\n",
    "            while \"Uses described in folk medicine\" not in page[i + n_lines] and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 2 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 2 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_traditional.append(output)\n",
    "\n",
    "# Folk with in-keyword:\n",
    "\n",
    "who_01_folk = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[3:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Uses described in folk medicine\" in line:\n",
    "            n_lines = 2\n",
    "            while page[i + n_lines] != \"Pharmacology\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 2 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 2 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_folk.append(output)\n",
    "\n",
    "who_01_con = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[4:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Contraindications\" in line and \"see\" not in line.lower():\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"Warnings\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_con.append(output)\n",
    "            \n",
    "who_01_warn = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[4:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Warnings\" in line and \"see\" not in line.lower():\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"Precautions\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_warn.append(output)\n",
    "            \n",
    "who_01_adv = list()\n",
    "\n",
    "ref_pattern = re.compile(r\"[0-9]+\\.\")  \n",
    "\n",
    "for page in who_01_pages_corrected[4:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Adverse reactions\" in line and \"see\" not in line.lower() and not re.search(ref_pattern, line):\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"Posology\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "                output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_adv.append(output)\n",
    "\n",
    "who_01_pos = list()\n",
    "  \n",
    "for page in who_01_pages_corrected[4:]:\n",
    "    max_len = len(page) - 1\n",
    "    for i, line in enumerate(page):\n",
    "        if \"Posology\" in line and \"and\" not in line.lower():\n",
    "            n_lines = 1\n",
    "            while page[i + n_lines] != \"References\" and i + n_lines < max_len:\n",
    "                n_lines += 1\n",
    "            if i + n_lines == max_len:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines + 1])\n",
    "                # output = re.sub(pattern_formula, \".\", output)\n",
    "            else:\n",
    "                output = \" \".join(page[i + 1 : i + n_lines])\n",
    "                # output = re.sub(pattern_formula, \".\", output)\n",
    "\n",
    "            if \".\" != output[-1]:\n",
    "                output = output.split(\".\")\n",
    "                output = output[:-1]\n",
    "                output = \".\".join(output)\n",
    "                output = output + \".\"\n",
    "\n",
    "            who_01_pos.append(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace WHO null values with empty string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = [\"No information available.\", \"None.\"]\n",
    "\n",
    "def make_nan(target_list: list):\n",
    "    for i, value in enumerate(target_list):\n",
    "        if value in null_values:\n",
    "            target_list[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_nan(who_01_clinical)\n",
    "make_nan(who_01_traditional)\n",
    "make_nan(who_01_folk)\n",
    "make_nan(who_01_con)\n",
    "make_nan(who_01_warn)\n",
    "make_nan(who_01_adv)\n",
    "make_nan(who_01_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_01_remedies = list()\n",
    "\n",
    "for i, definition in enumerate(who_01_def):\n",
    "\n",
    "    for name in duke_names:\n",
    "\n",
    "        remedy_dict = dict()\n",
    "        name = name.split(\" \")\n",
    "\n",
    "        # some taxonomic names have an \"x\", indicating hybrids\n",
    "        if \"x\" in name: \n",
    "            name.remove(\"x\")\n",
    "\n",
    "        if name[0] in definition and name[1] in definition:\n",
    "            remedy_dict[\"NAME\"] = \" \".join(name)\n",
    "            remedy_dict[\"DEF\"] = definition\n",
    "            remedy_dict[\"VERNAC\"] = who_01_vernacular[i]\n",
    "            remedy_dict[\"CLINICAL\"] = who_01_clinical[i]\n",
    "            remedy_dict[\"TRADITIONAL\"] = who_01_traditional[i] \n",
    "            remedy_dict[\"FOLK\"] = who_01_folk[i]\n",
    "            remedy_dict[\"CONTRAINDICATION\"] = who_01_con[i]\n",
    "            remedy_dict[\"WARNING\"] = who_01_warn[i]\n",
    "            remedy_dict[\"ADVERSE\"] = who_01_adv[i]\n",
    "            remedy_dict[\"POSOLOGY\"] = who_01_pos[i]\n",
    "\n",
    "        if remedy_dict:\n",
    "            who_01_remedies.append(remedy_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Duke dataframe:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading the modified ETHNOBOT dataset, a new serial index is created, so we need to drop the \"Unnamed: 0\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'TAXON', 'ACTIVITY', 'CNAME', 'FAMILY', 'GENUS',\n",
       "       'SPECIES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_duke_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAXON</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>CNAME</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>GENUS</th>\n",
       "      <th>SPECIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abelmoschus esculentus</td>\n",
       "      <td>Abortifacient,Antidote,Boil,Burn,Catarrh,Coffe...</td>\n",
       "      <td>nan,Huang Shu K'Uei,Bamia,Molondron,Quiabeiro,...</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>esculentus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abelmoschus manihot</td>\n",
       "      <td>Antitussive,Boil,Cancer,Cancer(Stomach),Catarr...</td>\n",
       "      <td>Tororo-Aoi,nan,Kastuli</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>manihot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abelmoschus moschatus</td>\n",
       "      <td>Aphrodisiac,Asthma,Bite(Snake),Boil,Cancer,Car...</td>\n",
       "      <td>Musk Mallow,nan,Moskus,Muskus,Mushk Dana,Amber...</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>moschatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abies alba</td>\n",
       "      <td>Bronchitis,Bruise,Calculus,Catarrh,Cough,Diure...</td>\n",
       "      <td>Abeto,Edeltanne,Beyaz Koknar,Silver Fir,Abeto ...</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>alba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abies balsamea</td>\n",
       "      <td>Burn,Cancer,Cold,Cough,Heart,Masticatory,Sore,...</td>\n",
       "      <td>nan,Balsam,Canada,Balsam Fir,Fir</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>balsamea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TAXON                                           ACTIVITY  \\\n",
       "0  Abelmoschus esculentus  Abortifacient,Antidote,Boil,Burn,Catarrh,Coffe...   \n",
       "1     Abelmoschus manihot  Antitussive,Boil,Cancer,Cancer(Stomach),Catarr...   \n",
       "2   Abelmoschus moschatus  Aphrodisiac,Asthma,Bite(Snake),Boil,Cancer,Car...   \n",
       "3              Abies alba  Bronchitis,Bruise,Calculus,Catarrh,Cough,Diure...   \n",
       "4          Abies balsamea  Burn,Cancer,Cold,Cough,Heart,Masticatory,Sore,...   \n",
       "\n",
       "                                               CNAME     FAMILY        GENUS  \\\n",
       "0  nan,Huang Shu K'Uei,Bamia,Molondron,Quiabeiro,...  Malvaceae  Abelmoschus   \n",
       "1                             Tororo-Aoi,nan,Kastuli  Malvaceae  Abelmoschus   \n",
       "2  Musk Mallow,nan,Moskus,Muskus,Mushk Dana,Amber...  Malvaceae  Abelmoschus   \n",
       "3  Abeto,Edeltanne,Beyaz Koknar,Silver Fir,Abeto ...   Pinaceae        Abies   \n",
       "4                   nan,Balsam,Canada,Balsam Fir,Fir   Pinaceae        Abies   \n",
       "\n",
       "      SPECIES  \n",
       "0  esculentus  \n",
       "1     manihot  \n",
       "2   moschatus  \n",
       "3        alba  \n",
       "4    balsamea  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = [\"TAXON\", \"ACTIVITY\", \"CNAME\", \"FAMILY\", \"GENUS\", \"SPECIES\"]\n",
    "rich_duke_df = mod_duke_df[target_cols]\n",
    "rich_duke_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data from WHO monographs to the reshaped dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing new columns in the enriched dataframe for the information stored in the remedy dictionary. Since we previously replaced all np.NaN values with a string \"nan\", the default value will be the same here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_duke_df[\"VERNAC\"] = \"nan\"\n",
    "rich_duke_df[\"CLINICAL\"] = \"nan\"\n",
    "rich_duke_df[\"TRADITIONAL\"] = \"nan\"\n",
    "rich_duke_df[\"FOLK\"] = \"nan\"\n",
    "rich_duke_df[\"CONTRAINDICATION\"] = \"nan\"\n",
    "rich_duke_df[\"WARNING\"] = \"nan\"\n",
    "rich_duke_df[\"ADVERSE\"] = \"nan\"\n",
    "rich_duke_df[\"POSOLOGY\"] = \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAXON</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>CNAME</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>GENUS</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>VERNAC</th>\n",
       "      <th>CLINICAL</th>\n",
       "      <th>TRADITIONAL</th>\n",
       "      <th>FOLK</th>\n",
       "      <th>CONTRAINDICATION</th>\n",
       "      <th>WARNING</th>\n",
       "      <th>ADVERSE</th>\n",
       "      <th>POSOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abelmoschus esculentus</td>\n",
       "      <td>Abortifacient,Antidote,Boil,Burn,Catarrh,Coffe...</td>\n",
       "      <td>nan,Huang Shu K'Uei,Bamia,Molondron,Quiabeiro,...</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>esculentus</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abelmoschus manihot</td>\n",
       "      <td>Antitussive,Boil,Cancer,Cancer(Stomach),Catarr...</td>\n",
       "      <td>Tororo-Aoi,nan,Kastuli</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>manihot</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abelmoschus moschatus</td>\n",
       "      <td>Aphrodisiac,Asthma,Bite(Snake),Boil,Cancer,Car...</td>\n",
       "      <td>Musk Mallow,nan,Moskus,Muskus,Mushk Dana,Amber...</td>\n",
       "      <td>Malvaceae</td>\n",
       "      <td>Abelmoschus</td>\n",
       "      <td>moschatus</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abies alba</td>\n",
       "      <td>Bronchitis,Bruise,Calculus,Catarrh,Cough,Diure...</td>\n",
       "      <td>Abeto,Edeltanne,Beyaz Koknar,Silver Fir,Abeto ...</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>alba</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abies balsamea</td>\n",
       "      <td>Burn,Cancer,Cold,Cough,Heart,Masticatory,Sore,...</td>\n",
       "      <td>nan,Balsam,Canada,Balsam Fir,Fir</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>Abies</td>\n",
       "      <td>balsamea</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TAXON                                           ACTIVITY  \\\n",
       "0  Abelmoschus esculentus  Abortifacient,Antidote,Boil,Burn,Catarrh,Coffe...   \n",
       "1     Abelmoschus manihot  Antitussive,Boil,Cancer,Cancer(Stomach),Catarr...   \n",
       "2   Abelmoschus moschatus  Aphrodisiac,Asthma,Bite(Snake),Boil,Cancer,Car...   \n",
       "3              Abies alba  Bronchitis,Bruise,Calculus,Catarrh,Cough,Diure...   \n",
       "4          Abies balsamea  Burn,Cancer,Cold,Cough,Heart,Masticatory,Sore,...   \n",
       "\n",
       "                                               CNAME     FAMILY        GENUS  \\\n",
       "0  nan,Huang Shu K'Uei,Bamia,Molondron,Quiabeiro,...  Malvaceae  Abelmoschus   \n",
       "1                             Tororo-Aoi,nan,Kastuli  Malvaceae  Abelmoschus   \n",
       "2  Musk Mallow,nan,Moskus,Muskus,Mushk Dana,Amber...  Malvaceae  Abelmoschus   \n",
       "3  Abeto,Edeltanne,Beyaz Koknar,Silver Fir,Abeto ...   Pinaceae        Abies   \n",
       "4                   nan,Balsam,Canada,Balsam Fir,Fir   Pinaceae        Abies   \n",
       "\n",
       "      SPECIES VERNAC CLINICAL TRADITIONAL FOLK CONTRAINDICATION WARNING  \\\n",
       "0  esculentus    nan      nan         nan  nan              nan     nan   \n",
       "1     manihot    nan      nan         nan  nan              nan     nan   \n",
       "2   moschatus    nan      nan         nan  nan              nan     nan   \n",
       "3        alba    nan      nan         nan  nan              nan     nan   \n",
       "4    balsamea    nan      nan         nan  nan              nan     nan   \n",
       "\n",
       "  ADVERSE POSOLOGY  \n",
       "0     nan      nan  \n",
       "1     nan      nan  \n",
       "2     nan      nan  \n",
       "3     nan      nan  \n",
       "4     nan      nan  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich_duke_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating the dictionary values to the correct dataframe column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_dict_values(remedy: dict, key: str):\n",
    "    name_filt = (rich_duke_df[\"TAXON\"] == remedy[\"NAME\"])\n",
    "    if  \"nan\" in rich_duke_df.loc[name_filt,[key]].values:\n",
    "        rich_duke_df.loc[name_filt,[key]] = remedy[key]\n",
    "    else:\n",
    "        rich_duke_df.loc[name_filt,[key]] = rich_duke_df.loc[name_filt,[key]] + remedy[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_keys = [\"NAME\", \"DEF\"]\n",
    "\n",
    "for i, herb in enumerate(who_01_remedies):\n",
    "    for key in herb.keys():\n",
    "        if key in skip_keys:\n",
    "            continue\n",
    "        store_dict_values(herb, key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better gauge the success of the previous code, we filter the dataframe to target one of the herbs that we know was in the monograph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAXON</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>CNAME</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>GENUS</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>VERNAC</th>\n",
       "      <th>CLINICAL</th>\n",
       "      <th>TRADITIONAL</th>\n",
       "      <th>FOLK</th>\n",
       "      <th>CONTRAINDICATION</th>\n",
       "      <th>WARNING</th>\n",
       "      <th>ADVERSE</th>\n",
       "      <th>POSOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Allium sativum</td>\n",
       "      <td>Ache(Ear),Ache(Stomach),Alopecia,Antidote,Anti...</td>\n",
       "      <td>nan,Thum,Suan,Hsiao Suan,Sarimsak,Ail,Sir,Ajo,...</td>\n",
       "      <td>Liliaceae</td>\n",
       "      <td>Allium</td>\n",
       "      <td>sativum</td>\n",
       "      <td>It is most commonly known as “garlic”,Ail,ail ...</td>\n",
       "      <td>As an adjuvant to dietetic management in the t...</td>\n",
       "      <td>The treatment of respiratory and urinary tract...</td>\n",
       "      <td>As an aphrodisiac, antipyretic, diuretic, emme...</td>\n",
       "      <td>Bulbus Allii Sativi is contraindicated in pati...</td>\n",
       "      <td>Consumption of large amounts of garlic may inc...</td>\n",
       "      <td>Bulbus Allii Sativi has been reported to evoke...</td>\n",
       "      <td>Unless otherwise prescribed, average daily dos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TAXON                                           ACTIVITY  \\\n",
       "473  Allium sativum  Ache(Ear),Ache(Stomach),Alopecia,Antidote,Anti...   \n",
       "\n",
       "                                                 CNAME     FAMILY   GENUS  \\\n",
       "473  nan,Thum,Suan,Hsiao Suan,Sarimsak,Ail,Sir,Ajo,...  Liliaceae  Allium   \n",
       "\n",
       "     SPECIES                                             VERNAC  \\\n",
       "473  sativum  It is most commonly known as “garlic”,Ail,ail ...   \n",
       "\n",
       "                                              CLINICAL  \\\n",
       "473  As an adjuvant to dietetic management in the t...   \n",
       "\n",
       "                                           TRADITIONAL  \\\n",
       "473  The treatment of respiratory and urinary tract...   \n",
       "\n",
       "                                                  FOLK  \\\n",
       "473  As an aphrodisiac, antipyretic, diuretic, emme...   \n",
       "\n",
       "                                      CONTRAINDICATION  \\\n",
       "473  Bulbus Allii Sativi is contraindicated in pati...   \n",
       "\n",
       "                                               WARNING  \\\n",
       "473  Consumption of large amounts of garlic may inc...   \n",
       "\n",
       "                                               ADVERSE  \\\n",
       "473  Bulbus Allii Sativi has been reported to evoke...   \n",
       "\n",
       "                                              POSOLOGY  \n",
       "473  Unless otherwise prescribed, average daily dos...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_alliumsativum = (rich_duke_df[\"TAXON\"] == \"Allium sativum\")\n",
    "rich_duke_df.loc[filt_alliumsativum]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this code successfully added the dictionary values to the dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
